{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import madmom\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import mean_pool, crop_image_patches\n",
    "from models import OLSPatchRegressor\n",
    "\n",
    "na = np.newaxis\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a mini database with patches from the spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "- add STFT options to the spectrogram (window size etc)\n",
    "- add possibility to use different options at the same time (add depth dimension, is there a problem with the resulting shape?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spectros_from_dir(audio_dir, max_samples = -1):\n",
    "    \n",
    "    audio_files = [f for f in listdir(audio_dir) if isfile(join(audio_dir, f))]\n",
    "    \n",
    "    if max_samples > 0:\n",
    "        audio_files = audio_files[:max_samples]\n",
    "    \n",
    "    # TODO: see above, could be handled here\n",
    "    spectro_function = lambda path: madmom.audio.spectrogram.Spectrogram(path).log()\n",
    "\n",
    "    # calc spectrogram for all files in the folder\n",
    "    spectrograms = np.array([spectro_function(join(audio_dir, af)) for af in audio_files])\n",
    "\n",
    "    # transorm to N, H, W shape\n",
    "    spectrograms = spectrograms.transpose(0, 2, 1) \n",
    "    \n",
    "    return spectrograms\n",
    "\n",
    "def show_in_grid(input_3d, instant_output=True, figsize=(20, 20), save_path = None):\n",
    "    \n",
    "    N, H, W = input_3d.shape\n",
    "\n",
    "    N_h = int(np.floor(N**.5))\n",
    "    N_w = N // N_h\n",
    "\n",
    "    hpad, wpad = 1, 1\n",
    "    pad_val = np.min(input_3d)\n",
    "\n",
    "    # add padding and grid presentation\n",
    "    padded_input = np.pad(input_3d[:N_h * N_w], [[0,0], [hpad,hpad], [wpad,wpad]], mode='constant', constant_values=pad_val)\n",
    "    H_padded = H + 2*wpad\n",
    "    W_padded = W + 2*hpad\n",
    "    spectro_grid = padded_input.reshape(N_h, N_w, H_padded, W_padded).transpose(0, 2, 1, 3).reshape(N_h* H_padded, N_w * W_padded)\n",
    "    \n",
    "    # present the grid\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(spectro_grid, origin='lower')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    \n",
    "    if instant_output:\n",
    "        plt.show()\n",
    "        \n",
    "def spectro_mini_db(music_dir, speech_dir, hpool=16, wpool=15, shuffle=True, max_samples = -1):\n",
    "    \n",
    "    music_spectros  = spectros_from_dir(music_dir, max_samples)\n",
    "    speech_spectros = spectros_from_dir(speech_dir, max_samples)\n",
    "    \n",
    "    X = np.concatenate([music_spectros, speech_spectros], axis=0)[:,:,:,na]\n",
    "    \n",
    "    # create labels, 1 for music, -1 for speech\n",
    "    Y = ((np.arange(X.shape[0]) < music_spectros.shape[0]) - .5) * 2\n",
    "    \n",
    "    if hpool > 0 and wpool > 0:\n",
    "        X = mean_pool(X, hpool, wpool)\n",
    "    \n",
    "    if shuffle:\n",
    "        I = np.random.permutation(X.shape[0])\n",
    "        \n",
    "        return X[I], Y[I]\n",
    "    else:\n",
    "        return X, Y\n",
    "    \n",
    "def crop_image_patches(X, h, w, hstride=1, wstride=1, return_2d_patches=False):\n",
    "    N, H, W, D =  X.shape\n",
    "    \n",
    "    assert(h <= H and w <=W)\n",
    "    \n",
    "    num_patches_h = (H - h) // hstride + 1\n",
    "    num_patches_w = (W - w) // wstride + 1\n",
    "    \n",
    "    patches = []\n",
    "    for h_idx in range(num_patches_h):\n",
    "        hstart = h_idx * hstride\n",
    "        \n",
    "        patches_w = []\n",
    "        for w_idx in range(num_patches_w):\n",
    "            wstart = w_idx * wstride\n",
    "            \n",
    "            patches_w.append(X[:,hstart:hstart + h, wstart:wstart + w, :])\n",
    "            \n",
    "        patches.append(patches_w)\n",
    "            \n",
    "    patches = np.array(patches)\n",
    "    \n",
    "    patches = patches.transpose(2, 0, 1, 3, 4, 5)\n",
    "    \n",
    "    if return_2d_patches:\n",
    "        return patches.reshape(N, num_patches_h, num_patches_w, h, w, D)\n",
    "    else:\n",
    "        return patches.reshape(N, num_patches_h * num_patches_w, h, w, D)\n",
    "\n",
    "def mean_pool(X, h, w):\n",
    "    N, H, W, D = X.shape\n",
    "    \n",
    "    assert(H % h == 0 and W % w == 0)\n",
    "    \n",
    "    NH = H // h\n",
    "    NW = W // w\n",
    "    \n",
    "    return X.reshape(N, NH * h, NW * w, D).reshape(N, NH, h, NW, w, D).mean(axis=(2, 4))\n",
    "\n",
    "def spectro_mini_db_patches(music_dir, speech_dir, patch_width, hpool = 16, wpool = 15, hstride=10, wstride=1, shuffle=True, max_samples = -1):\n",
    "    X, Y = spectro_mini_db(music_dir, speech_dir, hpool=hpool, wpool=wpool, shuffle=False, max_samples = max_samples)\n",
    "        \n",
    "    N, H, W, D = X.shape\n",
    "    \n",
    "    pos_idxs = Y > 0\n",
    "    neg_idxs = np.logical_not(pos_idxs)\n",
    "    \n",
    "    # crop patches from the images\n",
    "    X_patched_pos = crop_image_patches(X[pos_idxs], H, patch_width)\n",
    "    X_patched_neg = crop_image_patches(X[neg_idxs], H, patch_width)\n",
    "    \n",
    "    X_patched_pos = X_patched_pos.reshape(-1, *X_patched_pos.shape[2:])\n",
    "    X_patched_neg = X_patched_neg.reshape(-1, *X_patched_neg.shape[2:])\n",
    "\n",
    "    \n",
    "    num_pos = X_patched_pos.shape[0]\n",
    "    \n",
    "    X_patched = np.concatenate([X_patched_pos, X_patched_neg])\n",
    "    Y_patched = ((np.arange(X_patched.shape[0]) < num_pos) - .5) * 2\n",
    "    \n",
    "    if shuffle:\n",
    "        I = np.random.permutation(X_patched.shape[0])\n",
    "        return X_patched[I], Y_patched[I]\n",
    "    \n",
    "    else:\n",
    "        return X_patched, Y_patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed pooling, now X.shape: (128, 64, 100, 1)\n",
      "Performed pooling, now X.shape: (128, 64, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "music_dir  = '../data/music_speech/music_wav/'\n",
    "speech_dir = '../data/music_speech/speech_wav/'\n",
    "\n",
    "max_samples = -1\n",
    "\n",
    "X, Y = spectro_mini_db(music_dir, speech_dir, max_samples=max_samples)\n",
    "X_patched, Y_patched = spectro_mini_db_patches(music_dir, speech_dir, 10, hpool=16, wpool=15,  shuffle=False, max_samples=max_samples)\n",
    "\n",
    "print('Train Set Shape')\n",
    "print(X.shape, Y.shape)\n",
    "print('Patched Train Set Shape')\n",
    "print(X_patched.shape, Y_patched.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy (Patched): 0.8900240384615384\n",
      "Train Accuracy (Conv)   : 0.9296875\n"
     ]
    }
   ],
   "source": [
    "# Train linear patch regressor (att: no bias)\n",
    "regressor = OLSPatchRegressor()\n",
    "regressor.fit(X_patched, Y_patched)\n",
    "\n",
    "print('Train Accuracy (Patched): {}'.format(np.mean(np.sign(regressor.predict(X_patched, patch_mode=True)) == Y_patched)))\n",
    "\n",
    "ypred = regressor.predict(X)\n",
    "print('Train Accuracy (Conv)   : {}'.format(np.mean(np.sign(np.mean(ypred, axis=1)) == Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
